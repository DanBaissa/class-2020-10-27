---
title: "Notes 10 27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(PPBDS.data)
library(rstanarm)
library(tidyverse)
```

## Fitting a line

Last week we started using regression and it was an exciting but confusing time! Alexa wanted to know if we could use the data from class to determine if we see which departments require more or less hours of work. So we tried it! We ended up with something that looked like this:

```{r Regression}

fit_obj <- stan_glm(hours ~ department, data = qscores, refresh = 0)


fit_obj #Note we get an error likely because we have way too many predictors for observations

```

So what does this mean? For one, we had a glimpse into the future of what you all will be doing. But how can we understand this output?


## It starts with a line

Imagine we wanted to draw a line through the points to figure out how much work to expect in each department. 

What equation might we think of using? How about starting with the formula for a line that we learned in high school!!

y = mx + b

If we remember back to that time oh so long ago we know that b is the y-intercept and m is the slope and x is just x.

Now the question we might have, is how do we solve for m and b? 

There are many ways. We could just guess a number for m and b, but one really good way is by fitting a line through the points that minimizes the total distance from the line to all of the points. This is what linear regression tries to do!

When we think of regressions we simply rearange the equation.

y_hat = Beta_intercept + Beta * x

or for more complex models:

y_hat = Beta_intercept + Beta_1 * x_1 + Beta_2 * x_2 + ... + Beta_n * x_n

or

Estiamted Outcome = intercept + predicted slope 1 * variable 1 + predicted slope 2 * variable 2 + and so on

Now we could write this a different way if we don't like hats. We can bring the error term into the equation.



## Fitting a line

Now lets pretend we are the universe, the data generating machine, or one of the data gods and explore a relationship with data.

Lets predend that I created a new SAT and since I am not creative lets call it DSAT. It is normally distributed like the SAT with a mean of 500 and sd of 200.

Now lets say we want to predict y by DSAT score.


```{r dsat}

x_dsat <- rnorm(1000, 500, 200) 

a <- 2 # The intercept

beta <- 3

e <- rnorm(1000) #error term

y = a + beta * x_dsat + e 


```


So there we have it, a regression line! Done! 

If only we were the masters of the universe, right? Since we are not we will need tools to solve for for beta and a.

So lets try using regression here,

```{r regressing dsat}

dsat <- stan_glm(y ~ x_dsat , refresh = 0)
dsat

```

Check that out! Our fancy tool solved for beta and a perfectly! 

Now if we wanted to know how DSAT scores impact on y we can just put it back into our equation:

y = 2 + 3 * x

or 

```{r or}
2 + (3 * mean(x_dsat)) # For the average person

```


## Multiple Variables

You might be thinking, "well thats cool and all Dan but what about more variables?" 

Let's try it!

```{r more!}

a <- 2 # The intercept

x_dsat <- rnorm(1000, 500, 200) 

beta_dsat <- 3

x_dact <- rbinom(1000, 1, .7)

beta_dact <- -3.14159

x_3 <- rpois(1000, 4)

beta_3 <- 4

e <- rnorm(1000) #error term

y = a + (beta * x_dsat) + 
  (beta_dact * x_dact) + 
  (beta_3 * x_3) + e 



dsat2 <- stan_glm(y ~ x_dsat + x_dact + x_3, refresh = 0)
dsat2


```

Not much different!!

```{r dsat2}

2.1  + 3 * median(x_dsat) + -3.2 * median(x_dact) + 4 * median(x_3) # For the median person

```


What if we don't account for everything in our model?

```{r}

dsat_omit <- stan_glm(y ~ x_dsat, refresh = 0)
dsat_omit

```

We get the wrong answer. It can be even worse if you have interactions.

It is important to remember that stats tools are only as good as their user. 

When used incorrectly stats have been using to justify all kinds of nonsense.

For example, stats have been used to argue that minorities are will only be bad at sports, or they are only good at sports, have lower IQs, and so much more pseudoscience.

While this class doesn't focus on causality, I encurage you to think about whether there is a causal relationship.
For example, if color does cause lower IQs, then would we expect a white person's IQ to decline as they build up their tan? No? 
Maybe there is something wrong with your model or assumtions if you find that. Maybe Racism, socioeconomics, bias in testing, or perhaps one of 1000s more variables are interacting with race?


This is a very powerful tool, please think long and hard about how you are using it before you do.





## The answer for Alexa

So lets be clear, we have way too many betas for the estimate from last class, so take it with a grain of salt.

The varaibles for each department are considered dummy variables so 0 if no 1 if yes. 

Given that we multiply the beta for the department we are intersted by 1 otherwise the x is 0.

Since adding a bunch of 0s is messy I will just answer with the betas we care about to get the answer.

```{r}

# Gov hours:

3.8 + 2.2 


```

```{r}

# Econ hours:

3.8 + 2.6


```

```{r}

# Physics Hours:

3.8 +  6.3    
```


This is really lazy code. If you are finished early, maybe you can make this spiffier and develop CIs for these estimates?